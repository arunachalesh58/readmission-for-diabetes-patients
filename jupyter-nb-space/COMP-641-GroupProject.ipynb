{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e26d23d-8360-464d-9315-4716fca1762f",
   "metadata": {},
   "source": [
    "# COMP 641 Group Programming Project    \n",
    "\n",
    "**Project Title:** Predicting 30-Day Readmission in Diabetes Patients    \n",
    "\n",
    "__________________________________________________________________________________________________________________\n",
    "**Group Members:**  \n",
    "Aaron Hofman  \n",
    "Arunachalesh M Kembhavimath  \n",
    "Phone Pyae Zaw  \n",
    "Jaztin Tabunda  \n",
    "\n",
    "__________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ca8d6e-c514-43b7-949f-c031e98f3f72",
   "metadata": {},
   "source": [
    "## Data Science Project Instructions – Master’s Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c821a8-46a7-475e-96ef-fe31135ef925",
   "metadata": {},
   "source": [
    "Course Title: COMP 641 – Fundamentals of Data Science\n",
    "Project Title:  End to End Data Science Project\n",
    "Due Date: December 12, 2025\n",
    "\n",
    "Overview\n",
    "This project is a capstone-style assignment designed to apply the core concepts of data science covered throughout the course. You will identify a real-world problem, acquire and prepare data, conduct exploratory and statistical analysis, build and evaluate models, and present your findings in both technical and non-technical formats.\n",
    "\n",
    "Objectives\n",
    "By completing this project you will:\n",
    "        Frame a real-world problem in data science terms.\n",
    "        Collect, clean, and analyze data.\n",
    "        Apply data science methods (EDA, modeling, evaluation).\n",
    "        Communicate results effectively to stakeholders.\n",
    "        Practice reproducibility and ethical data practices.\n",
    "\n",
    "Proposal  Submission: (Due: Week 3)\n",
    "\n",
    "Submit a one-page proposal including:\n",
    "1. Project title and team members\n",
    "2. Problem statement\n",
    "3. Source of data (must be accessible)\n",
    "4. Planned methods/techniques (e.g., regression, classification, clustering)\n",
    "5. Ethical considerations\n",
    "\n",
    "Project Components\n",
    "\n",
    "Data Collection & Cleaning\n",
    "\n",
    "    Students must acquire data from a reliable source, such as public datasets, APIs, or through web scraping techniques.\n",
    "    Any challenges encountered during the data sourcing process should be clearly documented and explained.\n",
    "    Students must clean and preprocess the data, including handling missing values and performing appropriate feature engineering steps.\n",
    "\n",
    "Exploratory Data Analysis (EDA)\n",
    "\n",
    "    Students are required to visualize data trends, identify outliers, and explore data distributions to gain insight into the dataset.\n",
    "    At least three visualizations must be included, using tools such as matplotlib, seaborn, or similar libraries.\n",
    "    A written narrative must accompany the visualizations, summarizing key findings from the exploratory analysis.\n",
    "\n",
    "Modeling & Analysis\n",
    "\n",
    "    Students must choose appropriate machine learning models based on the nature of their problem, such as regression, clustering, or classification.\n",
    "    The dataset should be split into training and testing sets, or evaluated using cross-validation techniques.\n",
    "    Model performance must be assessed using relevant evaluation metrics, such as accuracy, RMSE, or AUC.\n",
    "\n",
    "Ethics & Bias Discussion\n",
    "\n",
    "    Students must identify and discuss any potential biases present in the data collection process or modeling approach.\n",
    "    The discussion should include the possible impact of these biases on stakeholders or end users of the system.\n",
    "\n",
    "Presentation (Due: December 12)\n",
    "\n",
    "Students are required to deliver a 5–10 minute in-class presentation summarizing their project. The presentation should clearly explain the problem addressed, the data used, the methods applied, and what are the key findings. Visual aids such as charts, graphs, or dashboards must be included to support the narrative. The presentation should be accessible to a broad audience and avoid excessive technical jargon.\n",
    "\n",
    " \n",
    "\n",
    "Final Report (Due: December 12)\n",
    "\n",
    "            Students must submit a technical report that is between 5 to 10 pages in length.\n",
    "            The report should include an introduction and clearly framed problem statement. A detailed description of the data and methodology used must be provided in the report. Students must present and interpret the results of their analysis and modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2e66f-d768-45a2-acd9-413cad91eb8e",
   "metadata": {},
   "source": [
    "## Project Environment Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3949e53-418b-490e-a44f-b3d1d2da3e5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Project Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "462cce9f-8b4f-4716-898e-7ca2e69009f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0287a57d-3efe-434c-8ead-d323dc3834d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Preparing CSV File paths for loading and Output Purposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132eeea-6be0-4199-ae9e-a5028ef67826",
   "metadata": {},
   "source": [
    "This is just to set up the paths where we will be saving the encoded dataset for the model and the place where the csv file is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54779994-4aec-46ae-abd4-339c607ca6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of diabetic_data.csv.\n",
    "# \"<insert file path of csv file/dataset>\"\n",
    "import_df_location = \"C:\\\\Users\\\\Jaztin T\\\\Downloads\\\\COMP-641-ProjectJupyterNotebook\\\\diabetic_data.csv\"\n",
    "# Locations for output files.\n",
    "# \"<insert file path of where you want output files to be>\"\n",
    "file_save_loaction = \"C:\\\\Users\\\\Jaztin T\\\\Downloads\\\\COMP-641-ProjectJupyterNotebook\"\n",
    "\n",
    "# File location provided check.\n",
    "if (import_df_location == \"\"):\n",
    "    raise ValueError(\"import_df_location cannot be empty.\")\n",
    "if (file_save_loaction == \"\"):\n",
    "    raise ValueError(\"file_save_loaction cannot be empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7118afb-4b79-4c61-9865-0b8cb0dea3ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setting up Variables for Output Text Information Files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc261cc0-9381-4836-b8cf-b6c030d4d40d",
   "metadata": {},
   "source": [
    "The following variables are used to produce the Output text files at the end of the notebook file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0191e11-6624-4245-92a1-b53c6dad2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output text.\n",
    "list_of_unique_and_nunique = \"\"\n",
    "check_duplicates_in_first_two = \"\"\n",
    "replacing_race_with_integers = \"\"\n",
    "replacing_gender_with_integers = \"\"\n",
    "replace_age_categories_with_integers = \"\"\n",
    "removing_weight_column = \"\"\n",
    "condensed_insurance_information = \"\"\n",
    "replacing_medical_specialty_with_integers = \"\"\n",
    "replacing_diagnoses_codes_with_integers = \"\"\n",
    "replacing_medication_used_indication_with_integers = \"\"\n",
    "replacing_max_glu_serum_with_integers = \"\"\n",
    "replacing_A1Cresult_with_integers = \"\"\n",
    "replacing_change_with_integers = \"\"\n",
    "replacing_diabetesMed_with_integers = \"\"\n",
    "replacing_readmitted_with_integers = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a48262-b5d2-47d1-9ac0-7aadd7f4344b",
   "metadata": {},
   "source": [
    "## Data Collection & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff6e126-fb06-454f-8b21-d2d6997a1e04",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data Loading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81530d45-78a0-4928-9647-f482fe6b5be0",
   "metadata": {},
   "source": [
    "The Main Diabetes Dataset is from diabetic_data.csv. This includes the information on hospital readmissions and patients.    \n",
    "\n",
    "The other datasets are originally from the IDS_mapping.csv  file. These datasets have the meaning of some columns values in the Main Diabetes Dataset. They were split from the IDS_mapping.csv to their own .csv files. Then they were loaded in to their respective dataframes for ease of use later in the EDA stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ea513ee-0b52-4c44-95a2-c329c291f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets and loading them into their respective dataframes (Assuming it's in the same directory as jupyter notebook file)\n",
    "# Main Diabetes dataset\n",
    "DiabetesDF = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Admission Source Type dataset. Derived from IDS_mapping.csv\n",
    "# combined with the main diabetes dataset, one can tell the origin of the patient prior to hospital admission\n",
    "admissionSourceDF = pd.read_csv('admission_source_types.csv')\n",
    "\n",
    "# Admission Type dataset. Derived from IDS_mapping.csv\n",
    "# combined with the main diabetes dataset, one can tell the patient's type of visit to the hospital (e.g. urgent, emergency, elective)\n",
    "admissionTypeDF = pd.read_csv('admission_type.csv')\n",
    "\n",
    "# Discharge disposition type dataset. Derived from IDS_mapping.csv\n",
    "# combined with the main diabetes dataset, one can tell where the patient went after discharge from hospital\n",
    "dischargeDispositionDF = pd.read_csv('discharge_disposition.csv')\n",
    "\n",
    "# dictionary of dataframes in case we want to loop through each dataframe later\n",
    "dataFrames = {\n",
    "    \"Diabetes Dataset\": DiabetesDF,\n",
    "    \"Admission Source Dataset\": admissionSourceDF,\n",
    "    \"Admission Type Dataset\": admissionTypeDF,\n",
    "    \"Discharge Disposition Dataset\": dischargeDispositionDF\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e5a4d-7847-43d7-8858-11b19d847be2",
   "metadata": {},
   "source": [
    "### Data Initial Inspection - Seeing what we are dealing with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92be5d2f-4ca3-41ee-9a86-0398d51348b8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Summary Overview of Each Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c66e609-7439-42e4-acaa-77b9415f34a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset----------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Source Dataset----------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 2 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   admission_source_id  25 non-null     int64 \n",
      " 1   description          24 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 532.0+ bytes\n",
      "None\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Type Dataset----------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   admission_type_id  8 non-null      int64 \n",
      " 1   description        7 non-null      object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 260.0+ bytes\n",
      "None\n",
      "----------------------------------------------\n",
      "\n",
      "Discharge Disposition Dataset----------------------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 2 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   discharge_disposition_id  30 non-null     int64 \n",
      " 1   description               29 non-null     object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 612.0+ bytes\n",
      "None\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each dataframe we have, we'll get a brief summary\n",
    "for name, dataFrame in dataFrames.items():\n",
    "    print(name + \"----------------------------------------------\\n\")\n",
    "    print(dataFrame.info())\n",
    "    print(\"----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2437406-a22d-40c0-ad9a-fd8d956aab5a",
   "metadata": {},
   "source": [
    "Looking at the information for each dataset, we find each dataset's data types, number of rows/entries, number of columns, and whether or not the datasets contain 'null' values. Firstly, looking at the diabetes dataset, one can see that the shape (rows x columns) of the dataset is 101766 rows/entries by 50 columns. Additionally, one can see that the dataset consists of integer values and strings/objects. Besides this, one may notice that most columns in the Diabetes dataset have non-null values in them. However, there are some columns that have null values. Namely, max_glu_serum and A1Cresult have a very low amount of non-null values in the dataset. To go into specifics, max_glu_serum has 5346 non-null values and A1Cresult has 17018 non-null values. Actions will most likely done on the columns later. Besides the main diabetes dataset, we have 'null' values in each dataset's \"description\" column. This doesn't seem problematic since it's only used for the mapping, so we don't really have to worry about those columns being null right now.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6841e6-ce4b-43ef-93fd-fad1a2d23769",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Column/Feature Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "529749e3-2205-4ceb-961b-9bfde23e48c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset----------------------------------------------\n",
      "\n",
      "List of columns/features for Diabetes Dataset:\n",
      " ['encounter_id', 'patient_nbr', 'race', 'gender', 'age', 'weight', 'admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'time_in_hospital', 'payer_code', 'medical_specialty', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'diag_1', 'diag_2', 'diag_3', 'number_diagnoses', 'max_glu_serum', 'A1Cresult', 'metformin', 'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride', 'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide', 'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone', 'tolazamide', 'examide', 'citoglipton', 'insulin', 'glyburide-metformin', 'glipizide-metformin', 'glimepiride-pioglitazone', 'metformin-rosiglitazone', 'metformin-pioglitazone', 'change', 'diabetesMed', 'readmitted'] \n",
      "\n",
      "Number of features:\n",
      "50\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Source Dataset----------------------------------------------\n",
      "\n",
      "List of columns/features for Admission Source Dataset:\n",
      " ['admission_source_id', 'description'] \n",
      "\n",
      "Number of features:\n",
      "2\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Type Dataset----------------------------------------------\n",
      "\n",
      "List of columns/features for Admission Type Dataset:\n",
      " ['admission_type_id', 'description'] \n",
      "\n",
      "Number of features:\n",
      "2\n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Discharge Disposition Dataset----------------------------------------------\n",
      "\n",
      "List of columns/features for Discharge Disposition Dataset:\n",
      " ['discharge_disposition_id', 'description'] \n",
      "\n",
      "Number of features:\n",
      "2\n",
      "\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for each dataframe we have, we'll point out some information about the columns \n",
    "# such as its number of features and the column names\n",
    "for name, dataFrame in dataFrames.items():\n",
    "    print(name + \"----------------------------------------------\\n\")\n",
    "    print(f\"List of columns/features for {name}:\\n {dataFrame.columns.tolist()} \\n\")\n",
    "    print(\"Number of features:\\n\" + str(len(dataFrame.columns.tolist())) + \"\\n\")\n",
    "    print(\"----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d069f6b-9b66-4a72-9d73-9de0914d2514",
   "metadata": {},
   "source": [
    "From looking at the information of each column, one can see the number of features in each dataset and what kind of information each dataset has.\n",
    "However, one can see that we would need to merge the dataset to get a better idea of what categorical description corresponds to a patient's visit. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47c47a-7fea-4898-9d4a-b21b264e0eb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### First Five Elements of each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dd5f6f1-0915-4aab-a0f0-a23cd36d0309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset----------------------------------------------\n",
      "\n",
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns] \n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Source Dataset----------------------------------------------\n",
      "\n",
      "   admission_source_id                                      description\n",
      "0                    1                               Physician Referral\n",
      "1                    2                                  Clinic Referral\n",
      "2                    3                                     HMO Referral\n",
      "3                    4                         Transfer from a hospital\n",
      "4                    5   Transfer from a Skilled Nursing Facility (SNF) \n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Admission Type Dataset----------------------------------------------\n",
      "\n",
      "   admission_type_id    description\n",
      "0                  1      Emergency\n",
      "1                  2         Urgent\n",
      "2                  3       Elective\n",
      "3                  4        Newborn\n",
      "4                  5  Not Available \n",
      "\n",
      "----------------------------------------------\n",
      "\n",
      "Discharge Disposition Dataset----------------------------------------------\n",
      "\n",
      "   discharge_disposition_id                                        description\n",
      "0                         1                                 Discharged to home\n",
      "1                         2  Discharged/transferred to another short term h...\n",
      "2                         3                      Discharged/transferred to SNF\n",
      "3                         4                      Discharged/transferred to ICF\n",
      "4                         5  Discharged/transferred to another type of inpa... \n",
      "\n",
      "----------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, dataFrame in dataFrames.items():\n",
    "    print(name + \"----------------------------------------------\\n\")\n",
    "    print(f\"{dataFrame.head(5)} \\n\")\n",
    "    print(\"----------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152eda04-b22e-435f-904c-617e6280a530",
   "metadata": {},
   "source": [
    "Upon looking at the first five elements of each data, one can see the type of data we are dealing with, and some obvious issues. One obvious issue is the fact that the first 5 rows lack a weight value in the Diabetes dataset. In other words, the weight column should most likely be excluded since it doesn't look like we can get valuable information from it. Additionally, it shows that one would have to look out for \"?\" values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f1dca-1fbc-4a3e-85b6-6fa3027b78d7",
   "metadata": {},
   "source": [
    "#### Missing value counts per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86b039af-cc75-4104-93b2-20bd7e4261bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes Dataset's Missing Value Counts Per Column:-------------------------------------------------------------\n",
      "\n",
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                            0\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                          0\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                      0\n",
      "medical_specialty               0\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                          0\n",
      "diag_2                          0\n",
      "diag_3                          0\n",
      "number_diagnoses                0\n",
      "max_glu_serum               96420\n",
      "A1Cresult                   84748\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "\n",
      "Admission Source Dataset's Missing Value Counts Per Column:-------------------------------------------------------------\n",
      "\n",
      "admission_source_id    0\n",
      "description            1\n",
      "dtype: int64\n",
      "\n",
      "Admission Type Dataset's Missing Value Counts Per Column:-------------------------------------------------------------\n",
      "\n",
      "admission_type_id    0\n",
      "description          1\n",
      "dtype: int64\n",
      "\n",
      "Discharge Disposition Dataset's Missing Value Counts Per Column:-------------------------------------------------------------\n",
      "\n",
      "discharge_disposition_id    0\n",
      "description                 1\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, dataFrame in dataFrames.items():\n",
    "    print(name + \"'s Missing Value Counts Per Column:-------------------------------------------------------------\\n\")\n",
    "    print(str(dataFrame.isna().sum()) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9fa849-6221-41e7-a9a1-f003148c0497",
   "metadata": {},
   "source": [
    "From just glancing at the \"missing value counts per column\", as stated previously, one might come to the conclusion that only max_glu_serum (94% null) and A1Cresult (83% null) have missing values. However, we need to also consider that other columns in the diabetes dataset mark empty data cells with \"?\" mark. With that being said, merging the other datasets into the main diabetes datasets will be done to get a more accurate number of \"null\" values. Additionally, the count will include looking at rows with \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd969d1e-2508-4e8b-bfaf-dd282a2d2514",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Looking for Unique Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97218e2-efc1-43a5-b233-ba54e9d97dd9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### For Output Text Information File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fdad0665-9658-4fa5-bb17-98ec18910db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method that prints both a list of the unique elements and the number of unique elements from a provided column name.\n",
    "# The user can also state when this print method was used.\n",
    "def unique_element_and_count_string(column_name, before_or_after_or_empty):\n",
    "    string_to_return = f\"Unique Elements {before_or_after_or_empty}: {str(DiabetesDF[column_name].unique())}\\n\"\n",
    "    string_to_return += f\"Unique Element Count {before_or_after_or_empty}: {str(DiabetesDF[column_name].nunique())}\\n\"\n",
    "    return string_to_return\n",
    "\n",
    "column_names_list = DiabetesDF.columns.tolist()\n",
    "# Save list and count of unique elements from each column.\n",
    "list_of_unique_and_nunique += \"List and count of unique elements from each column in dataframe.\\n\"\n",
    "for element in column_names_list:\n",
    "    list_of_unique_and_nunique += f\"Column Name: {element}\\n\"\n",
    "    list_of_unique_and_nunique += unique_element_and_count_string(element, \"\")\n",
    "    list_of_unique_and_nunique += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f15af8ee-01ae-458b-9858-d0a0da72ce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in encounter_id and patient_nbr.\n",
    "first_two_column_names = column_names_list[:2]\n",
    "list_of_groups = []\n",
    "for element in first_two_column_names:\n",
    "    current_duplicate_check = DiabetesDF.groupby(element)\n",
    "    list_of_groups.append(current_duplicate_check)\n",
    "check_duplicates_in_first_two += \"During earlier analysis, duplicate elements were found in patient_nbr.\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8e36b5-fa83-4943-92d7-c1c849f8454b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Making Adjustments to the Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5378f32-a33f-4dca-aa60-ab46c3b02dcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Drop Weight Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e420f-a7cf-485f-9fee-4adb7352e1a1",
   "metadata": {},
   "source": [
    "We drop the weight column because almost 97% of values are blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a01d081-ed0e-44a9-a436-c786a03881fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'weight' column, axis = 1 basically means drop the entire column. axis = 0 means drop the rows\n",
    "DiabetesDF.drop('weight', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971cf09c-a9fe-415f-97c9-33b8d6de1152",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### For Output Text Information File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "591cbf30-7115-46ed-b232-a077ce051a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print drop reason.\n",
    "removing_weight_column += \"Dropped 'weight' column due to too many missing elements (97% missing).\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be05c4a-9e4a-4b5e-a3e1-a217992e3849",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddfd1aa-2264-4d59-80dd-f7b91fbecfc9",
   "metadata": {},
   "source": [
    "## Modeling & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd6fea-c1ff-436b-82c1-b82c3127e8e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Encoding - Preparing the dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "45cb64a2-55a2-43f0-89b0-ab8bea3e0bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace race text with integers.\n",
    "replacing_race_with_integers += \"Column Name: Race\\n\"\n",
    "# Print replacement information.\n",
    "replacing_race_with_integers += \"Replacements:\\n'?' --> 0\\n'Caucasian' --> 1\\n'AfricanAmerican' --> 2\\n'Asian' --> 3\\n'Hispanic' --> 4\\n'Other' --> 5\\n'Anything Else' --> -1\\n\"\n",
    "# Print list of unique elements beforehand.\n",
    "replacing_race_with_integers += unique_element_and_count_string(\"race\", \"before\")\n",
    "# Replacement function.\n",
    "def replace_race_text(input_information):\n",
    "    match input_information:\n",
    "        case '?': # If '?' (not provided), return 0.\n",
    "            return 0\n",
    "        case 'Caucasian':\n",
    "            return 1\n",
    "        case 'AfricanAmerican':\n",
    "            return 2\n",
    "        case 'Asian':\n",
    "            return 3\n",
    "        case 'Hispanic':\n",
    "            return 4\n",
    "        case 'Other':\n",
    "            return 5\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['race'] = DiabetesDF['race'].apply(lambda x: replace_race_text(x))\n",
    "# Print list of unique elements afterward to ensure replacement.\n",
    "replacing_race_with_integers += unique_element_and_count_string(\"race\", \"after\")\n",
    "replacing_race_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70faca00-76ed-47b5-9cde-2696609e9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace gender text with integers.\n",
    "replacing_gender_with_integers += \"Column Name: gender\\n\"\n",
    "# Print replacement information.\n",
    "replacing_gender_with_integers += \"Replacements:\\n'Unknown/Invalid' --> 0\\n'Male' --> 1\\n'Female' --> 2\\n'Anything Else' --> -1\\n\"\n",
    "# Print list of unique elements beforehand.\n",
    "replacing_gender_with_integers += unique_element_and_count_string(\"gender\", \"before\")\n",
    "# Replacement function.\n",
    "def replace_gender(input_information):\n",
    "    match input_information:\n",
    "        case 'Unknown/Invalid':\n",
    "            return 0\n",
    "        case 'Male':\n",
    "            return 1\n",
    "        case 'Female':\n",
    "            return 2\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['gender'] = DiabetesDF['gender'].apply(lambda x: replace_gender(x))\n",
    "# Print list of unique elements afterward to ensure replacement.\n",
    "replacing_gender_with_integers += unique_element_and_count_string(\"gender\", \"after\")\n",
    "replacing_gender_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "511e4737-2b40-40b0-88aa-9ae33022db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace age text with integers.\n",
    "replace_age_categories_with_integers += \"Column Name: age\\n\"\n",
    "# Print replacement information.\n",
    "replace_age_categories_with_integers += \"Replacements:\\n'[0-10)' --> 0\\n'[10-20)' --> 1\\n'[20-30)' --> 2\\n'[30-40)' --> 3\\n'[40-50)' --> 4\\n'[50-60)' --> 5\\n'[60-70)' --> 6\\n'[70-80)' --> 7\\n'[80-90)' --> 8\\n'[90-100)' --> 9\\n'Anything Else' --> -1\\n\"\n",
    "# Print list of unique elements beforehand.\n",
    "replace_age_categories_with_integers += unique_element_and_count_string(\"age\", \"before\")\n",
    "# Replacement function.\n",
    "def replace_age_ranges(input_information):\n",
    "    match input_information:\n",
    "        case '[0-10)':\n",
    "            return 0\n",
    "        case '[10-20)':\n",
    "            return 1\n",
    "        case '[20-30)':\n",
    "            return 2\n",
    "        case '[30-40)':\n",
    "            return 3\n",
    "        case '[40-50)':\n",
    "            return 4\n",
    "        case '[50-60)':\n",
    "            return 5\n",
    "        case '[60-70)':\n",
    "            return 6\n",
    "        case '[70-80)':\n",
    "            return 7\n",
    "        case '[80-90)':\n",
    "            return 8\n",
    "        case '[90-100)':\n",
    "            return 9\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['age'] = DiabetesDF['age'].apply(lambda x: replace_age_ranges(x))\n",
    "# Print list of unique elements afterward to ensure replacement.\n",
    "replace_age_categories_with_integers += unique_element_and_count_string(\"age\", \"after\")\n",
    "replace_age_categories_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5674c2a1-edb6-459a-9629-667d902f8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condense insurance information.\n",
    "condensed_insurance_information += \"Column Name: payer_code\\n\"\n",
    "# Print condensing information.\n",
    "condensed_insurance_information += \"Condensing:\\n'?' --> 0\\n'SP' --> 1\\n'Anything Else' --> 2\\n\"\n",
    "# Print reason for condensing.\n",
    "condensed_insurance_information += \"Reason for condensing:\\nPatients who don't use insurance are less likely to return for additional treatment, which puts them at increased risk for further injury.\\n\"\n",
    "# Print list of unique elements beforehand.\n",
    "condensed_insurance_information += unique_element_and_count_string(\"payer_code\", \"before\")\n",
    "# Filtering function.\n",
    "def filter_payer_code(input_information):\n",
    "    # Insurance information not provided.\n",
    "    if (input_information == '?'):\n",
    "        return 0\n",
    "    # Patient did not use insurance. I don't know if 'SP' stands for 'self-pay' or not.\n",
    "    elif (input_information == 'SP'):\n",
    "        return 1\n",
    "    # Patient used insurance.\n",
    "    else:\n",
    "        return 2\n",
    "# Perform the filtering operation.\n",
    "DiabetesDF['payer_code'] = DiabetesDF['payer_code'].apply(lambda x: filter_payer_code(x))\n",
    "# Print list of unique elements afterward to ensure filtering.\n",
    "condensed_insurance_information += unique_element_and_count_string(\"payer_code\", \"after\")\n",
    "condensed_insurance_information += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8e6650f4-3357-4bd5-a95c-b87c105dd44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the elements in a given column with integers.\n",
    "def replace_elements_with_ints(column_name):\n",
    "    return_question_mark_associated_element = 0\n",
    "\n",
    "    # Get the list of unique column elements from the column in question.\n",
    "    unique_column_elements = DiabetesDF[column_name].unique().tolist()\n",
    "\n",
    "    # Check if a '?' element exists, and move it to the front of the list of unique column elements if it does.\n",
    "    try:\n",
    "        question_mark_location = unique_column_elements.index('?')\n",
    "        unique_column_elements.pop(question_mark_location)\n",
    "        unique_column_elements.insert(0, '?')\n",
    "\n",
    "        # Additional information needs to be printed\n",
    "        if (question_mark_location == 0):\n",
    "            return_question_mark_associated_element = 1\n",
    "        if (question_mark_location > 0):\n",
    "            return_question_mark_associated_element = 2\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Convert back to numpy array for printing purposes.\n",
    "    unique_column_elements = np.array(unique_column_elements)\n",
    "\n",
    "    # Get the number of unique column elements from the column in question, and then generate a list of elements from 0 up to one less than the number of unique elements.\n",
    "    unique_column_element_count = DiabetesDF[column_name].nunique()\n",
    "    list_of_numbers = list(range(0, unique_column_element_count))\n",
    "\n",
    "    # Pair each number to a unique column element and perform the replacement.\n",
    "    unique_column_elements_numbers_pairing = {key: element for key, element in zip(unique_column_elements, list_of_numbers)}\n",
    "    DiabetesDF[column_name] = DiabetesDF[column_name].apply(lambda x: unique_column_elements_numbers_pairing[x])\n",
    "\n",
    "    # If a '?' element exists, the temporary reordering of unique elements was done, so additional information needs to be printed.\n",
    "    if (return_question_mark_associated_element == 1):\n",
    "        return f\"The element associated with '?' is '{unique_column_elements_numbers_pairing['?']}'\\n\"\n",
    "    elif (return_question_mark_associated_element == 2):\n",
    "        return (\n",
    "            f\"Temporary reordering of unique elements: {unique_column_elements}\\n\" +\n",
    "            f\"The element associated with '?' is '{unique_column_elements_numbers_pairing['?']}'\\n\"\n",
    "            )\n",
    "    else:\n",
    "        return \"\"\n",
    "# Replacement information.\n",
    "replace_elements_with_ints_string = \"Replacement:\\nEverything --> After moving '?' (if it exists) to the front of the unique elements list, each element is assigned a unique number, starting from zero up to one less than the number of unique elements.\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8e58a17-8dce-45bb-82ac-ea409d13b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing medical specialty strings with integers.\n",
    "# Despite 53% of element missing, the medical speciality examining a patient is very important.\n",
    "#  Example: Emergency/Trauma is much more important than Dentistry.\n",
    "def consensing_medical_specialties(input_information):\n",
    "    match input_information:\n",
    "        # Primary Care\n",
    "        case x if (x == 'Family/GeneralPractice') or (x == 'InternalMedicine') or (x == 'Pediatrics') or (x == 'Hospitalist') or (x == 'Osteopath') or (x == 'Resident') or (x == 'PhysicianNotFound'):\n",
    "            return 'Primary Care'\n",
    "        # Cardiovascular System - Non-surgery.\n",
    "        case x if (x == 'Cardiology') or (x == 'Cardiology-Pediatric'):\n",
    "            return 'Cardiovascular System - Non-surgery'\n",
    "        # Neurology - Non-surgery.\n",
    "        case x if (x == 'Neurology') or (x == 'Neurophysiology') or (x == 'Pediatrics-Neurology'):\n",
    "            return 'Neurology - Non-surgery'\n",
    "        # Psychiatry\n",
    "        case x if (x == 'Psychiatry') or (x == 'Psychiatry-Child/Adolescent') or (x == 'Psychiatry-Addictive') or (x == 'Psychology'):\n",
    "            return 'Psychiatry'\n",
    "        case _:\n",
    "            return input_information\n",
    "# Condense some of the related medical specialities into groups.\n",
    "replacing_medical_specialty_with_integers += \"Column Name: medical_specialty\\n\"\n",
    "# Perform consensing.\n",
    "DiabetesDF['medical_specialty'] = DiabetesDF['medical_specialty'].apply(lambda x: consensing_medical_specialties(x))\n",
    "# Print list and number of unique elements after condensing.\n",
    "replacing_medical_specialty_with_integers += unique_element_and_count_string('medical_specialty', \"After Condensing\")\n",
    "# Print notes.\n",
    "replacing_medical_specialty_with_integers += (\"Notes:\\nDespite 53% of elements missing, the medical speciality examining a patient is very important.\\n\" +\n",
    "                                              \"Example:\\nEmergency/Trauma is much more important than Dentistry.\\n\" + \n",
    "                                              \"In addition, 'DCPTEAM' possibly stands for 'Dynamic Care Planning Team'.\\n\")\n",
    "# Print replacement message.\n",
    "replacing_medical_specialty_with_integers += replace_elements_with_ints_string\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_medical_specialty_with_integers += unique_element_and_count_string(\"medical_specialty\", \"before\")\n",
    "# Perform replacement.\n",
    "replacing_medical_specialty_with_integers += replace_elements_with_ints('medical_specialty')\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_medical_specialty_with_integers += unique_element_and_count_string(\"medical_specialty\", \"after\")\n",
    "replacing_medical_specialty_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d37b8d8a-208d-4000-9950-3e84ced9740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the codes for diagnoses 1, 2, and 3 with integers.\n",
    "for i in range(18, 21):\n",
    "    current_column_name = column_names_list[i]\n",
    "    # Print column name.\n",
    "    replacing_diagnoses_codes_with_integers += f\"Column Name: {current_column_name}\\n\"\n",
    "    # Print reason for replacement.\n",
    "    replacing_diagnoses_codes_with_integers += replace_elements_with_ints_string\n",
    "    # Print list and number of unique elements beforehand.\n",
    "    replacing_diagnoses_codes_with_integers += unique_element_and_count_string(current_column_name, \"before\")\n",
    "    # Perform replacement.\n",
    "    replacing_diagnoses_codes_with_integers += replace_elements_with_ints(current_column_name)\n",
    "    # Print list and number of unique elements afterward to ensure replacement.\n",
    "    replacing_diagnoses_codes_with_integers += unique_element_and_count_string(current_column_name, \"after\")\n",
    "    replacing_diagnoses_codes_with_integers += \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d5db5947-2dc1-4c14-bf10-711470776923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace no, steady, up, and down with corresponding integers.\n",
    "def replace_no_steady_up_down(input_information):\n",
    "    match input_information.lower():\n",
    "        case 'no':\n",
    "            return 0\n",
    "        case 'steady':\n",
    "            return 1\n",
    "        case 'up':\n",
    "            return 2\n",
    "        case 'down':\n",
    "            return 3\n",
    "        case _:\n",
    "            return -1\n",
    "# Print medication note.\n",
    "replacing_medication_used_indication_with_integers += \"Medication Note:\\nWhile some medications were not administered, medications are still important and, as a result, they weren't dropped.\\n\\n\"\n",
    "for i in range(24, 47):\n",
    "    current_column_name = column_names_list[i]\n",
    "    # Print column name.\n",
    "    replacing_medication_used_indication_with_integers += f\"Column Name: {current_column_name}\\n\"\n",
    "    # Print reason for replacement.\n",
    "    replacing_medication_used_indication_with_integers += \"Replacements:\\n'no' --> 0\\n'steady' --> 1\\n'up' --> 2\\n'down' --> 3\\n'Anything Else' --> -1\\n\"\n",
    "    # Print list and number of unique elements beforehand.\n",
    "    replacing_medication_used_indication_with_integers += unique_element_and_count_string(current_column_name, \"before\")\n",
    "    # Perform replacement.\n",
    "    DiabetesDF[current_column_name] = DiabetesDF[current_column_name].apply(lambda x: replace_no_steady_up_down(x))\n",
    "    # Print list and number of unique elements afterward to ensure replacement.\n",
    "    replacing_medication_used_indication_with_integers += unique_element_and_count_string(current_column_name, \"after\")\n",
    "    replacing_medication_used_indication_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdea7bcd-a6a1-40d1-b238-45c27ed5a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in 'max_glu_serum' column.\n",
    "replacing_max_glu_serum_with_integers += \"Column Name: max_glu_serum\\n\"\n",
    "# Print replacement information.\n",
    "replacing_max_glu_serum_with_integers += \"Replacements:\\n'nan' --> 0\\n'norm' --> 1\\n'>200' --> 2\\n'>300' --> 3\\n'Anything Else' --> -1\\n\"\n",
    "# Print note.\n",
    "replacing_max_glu_serum_with_integers += \"Note:\\n'None' in the excel sheet might be 'nan' in Pandas. That explains the jump from 3 to 4 in the number of unique elements.\\n\"\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_max_glu_serum_with_integers += unique_element_and_count_string(\"max_glu_serum\", \"before\")\n",
    "# Replace elements with corresponding integers.\n",
    "def replace_max_glu_serum_elements(input_information):\n",
    "    match str(input_information).lower():\n",
    "        case 'nan':\n",
    "            return 0\n",
    "        case 'norm':\n",
    "            return 1\n",
    "        case '>200':\n",
    "            return 2\n",
    "        case '>300':\n",
    "            return 3\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['max_glu_serum'] = DiabetesDF['max_glu_serum'].apply(lambda x: replace_max_glu_serum_elements(x))\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_max_glu_serum_with_integers += unique_element_and_count_string(\"max_glu_serum\", \"after\")\n",
    "replacing_max_glu_serum_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9508fcab-7047-45d9-b3d7-c89af610c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in 'A1Cresult' column.\n",
    "replacing_A1Cresult_with_integers += \"Column Name: A1Cresult\\n\"\n",
    "# Perform replacement information.\n",
    "replacing_A1Cresult_with_integers += \"Replacements:\\n'nan' --> 0\\n'norm' --> 1\\n'>7' --> 2\\n'>8' --> 3\\n'Anything Else' --> -1\\n\"\n",
    "# Print note.\n",
    "replacing_A1Cresult_with_integers += \"Note:\\n'None' in the excel sheet might be 'nan' in Pandas. That explains the jump from 3 to 4 in the number of unique elements.\\n\"\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_A1Cresult_with_integers += unique_element_and_count_string(\"A1Cresult\", \"before\")\n",
    "# Replace elements with corresponding integers.\n",
    "def replace_A1Cresult_elements(input_information):\n",
    "    match str(input_information).lower():\n",
    "        case 'nan':\n",
    "            return 0\n",
    "        case 'norm':\n",
    "            return 1\n",
    "        case '>7':\n",
    "            return 2\n",
    "        case '>8':\n",
    "            return 3\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['A1Cresult'] = DiabetesDF['A1Cresult'].apply(lambda x: replace_A1Cresult_elements(x))\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_A1Cresult_with_integers += unique_element_and_count_string(\"A1Cresult\", \"after\")\n",
    "replacing_A1Cresult_with_integers += \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "471a834d-5864-410d-92bd-8bf71b41e8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in 'change' column.\n",
    "replacing_change_with_integers += \"Column Name: change\\n\"\n",
    "# Print replacement information.\n",
    "replacing_change_with_integers += \"Replacements:\\n'no' --> 0\\n'ch' --> 1\\n'Anything Else' --> -1\\n\"\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_change_with_integers += unique_element_and_count_string(\"change\", \"before\")\n",
    "# Replace elements with corresponding integers.\n",
    "def replace_change_elements(input_information):\n",
    "    match str(input_information).lower():\n",
    "        case 'no':\n",
    "            return 0\n",
    "        case 'ch':\n",
    "            return 1\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['change'] = DiabetesDF['change'].apply(lambda x: replace_change_elements(x))\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_change_with_integers += unique_element_and_count_string(\"change\", \"after\")\n",
    "replacing_change_with_integers += \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "98c4ccef-fa1c-44aa-b069-76a216d1653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in 'diabetesMed' column.\n",
    "replacing_diabetesMed_with_integers += \"Column Name: diabetesMed\\n\"\n",
    "# Print replacement information.\n",
    "replacing_diabetesMed_with_integers += \"Replacements:\\n'no' --> 0\\n'yes' --> 1\\n'Anything Else' --> -1\\n\"\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_diabetesMed_with_integers += unique_element_and_count_string(\"diabetesMed\", \"before\")\n",
    "# Replace elements with corresponding integers.\n",
    "def replace_diabetesMed_elements(input_information):\n",
    "    match str(input_information).lower():\n",
    "        case 'no':\n",
    "            return 0\n",
    "        case 'yes':\n",
    "            return 1\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['diabetesMed'] = DiabetesDF['diabetesMed'].apply(lambda x: replace_diabetesMed_elements(x))\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_diabetesMed_with_integers += unique_element_and_count_string(\"diabetesMed\", \"after\")\n",
    "replacing_diabetesMed_with_integers += \"\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a17596d4-bcaf-4474-a14d-6d009314f860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace elements in 'readmitted' column.\n",
    "replacing_readmitted_with_integers += \"Column Name: readmitted\\n\"\n",
    "# Print replacement information.\n",
    "replacing_readmitted_with_integers += \"Replacements:\\n'no' --> 0\\n'<30' --> 1\\n'>30' --> 2\\n'Anything Else' --> -1\\n\"\n",
    "# Print list and number of unique elements beforehand.\n",
    "replacing_readmitted_with_integers += unique_element_and_count_string(\"readmitted\", \"before\")\n",
    "# Replace elements with corresponding integers.\n",
    "def replace_readmitted_elements(input_information):\n",
    "    match str(input_information).lower():\n",
    "        case 'no':\n",
    "            return 0\n",
    "        case '<30':\n",
    "            return 1\n",
    "        case '>30':\n",
    "            return 2\n",
    "        case _:\n",
    "            return -1\n",
    "# Perform replacement.\n",
    "DiabetesDF['readmitted'] = DiabetesDF['readmitted'].apply(lambda x: replace_readmitted_elements(x))\n",
    "# Print list and number of unique elements afterward to ensure replacement.\n",
    "replacing_readmitted_with_integers += unique_element_and_count_string(\"readmitted\", \"after\")\n",
    "replacing_readmitted_with_integers += \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d241f145-db03-4441-94e2-97e7c91309bc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Creating the Encoded CSV Files and Text Information Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a987282f-a595-44b4-a8eb-a6c1caaa6ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Outputting information to text files.\")\n",
    "# final_output_string_1 = (\n",
    "#     \"Below, please find a list of the unique elements in each column along with how many unique elements there are.\\n\\n\\n\"\n",
    "#     f\"{list_of_unique_and_nunique}\\n\\n\"\n",
    "# )\n",
    "# final_output_string_2 = (\n",
    "#     \"Introductory Info:\\n\"\n",
    "#     \"This file: Information on the modifications done to the diabetic_data.csv file and why they were done.\\n\"\n",
    "#     \"unique_information.txt: A list of unique elements in each column along with how many unique elements there are.\\n\"\n",
    "#     \"output.csv: A version of diabetic_data.csv modified with the edits described in this file.\\n\"\n",
    "#     \"output_grouped.csv: A version of output.csv where everything has been grouped together based on patient_nbr.\\n\"\n",
    "#     \"Percentages for the amount of missing elements for some of the columns can be found here: https://onlinelibrary.wiley.com/doi/10.1155/2014/781670\\n\\n\\n\\n\\n\"\n",
    "#     \"Modifications to diabetic_data.csv:\\n\\n\\n\"\n",
    "#     f\"{check_duplicates_in_first_two}\\n\\n\"\n",
    "#     f\"{replacing_race_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_gender_with_integers}\\n\\n\"\n",
    "#     f\"{replace_age_categories_with_integers}\\n\\n\"\n",
    "#     f\"{removing_weight_column}\\n\\n\"\n",
    "#     f\"{condensed_insurance_information}\\n\\n\"\n",
    "#     f\"{replacing_medical_specialty_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_diagnoses_codes_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_medication_used_indication_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_max_glu_serum_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_A1Cresult_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_change_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_diabetesMed_with_integers}\\n\\n\"\n",
    "#     f\"{replacing_readmitted_with_integers}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64d8770a-39fa-48ac-b60f-30aff57b4937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save unique element and count information to text file.\n",
    "# with open(\"unique_information.txt\", 'w') as file:\n",
    "#     file.write(final_output_string_1)\n",
    "# # Save explanation information to text file.\n",
    "# with open(\"explanation_information.txt\", 'w') as file:\n",
    "#     file.write(final_output_string_2)\n",
    "# print(\"Information outputted to text file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ab67daaa-7066-4e43-b196-82e7d118b77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create modified csv file from resulting dataframe.\n",
    "# print(\"Outputting modified csv file.\")\n",
    "# DiabetesDF.to_csv(os.path.join(file_save_loaction, 'output.csv'), index=False)\n",
    "# print(\"Modified csv file outputted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc50e518-0471-46a2-9fe9-92b1b990a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group resulting dataframe by the 'patient_nbr' column.\n",
    "# print(\"Starting Grouping\")\n",
    "# tqdm.pandas()\n",
    "# # https://stackoverflow.com/questions/60963409/creating-a-dictionary-of-dictionaries-from-groupby\n",
    "# DiabetesDF_grouped = DiabetesDF.groupby('patient_nbr')\n",
    "# group_of_groups = DiabetesDF_grouped.progress_apply(lambda x: x.set_index('encounter_id').to_dict())\n",
    "# print(\"Grouping Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb1011b6-6fe4-49b1-b6c8-e845def4c040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create grouped csv file from the grouped dataframe.\n",
    "# print(\"Outputting grouped version of modified csv file.\")\n",
    "# group_of_groups.to_csv(os.path.join(file_save_loaction, 'output_grouped.csv'), index=False)\n",
    "# print(\"Grouped version of modified csv file outputted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa20908-fa6b-4d1a-a9fc-c7362ba340a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb004ed5-9f63-404d-8440-bc5a515c2169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c425bc-be7b-44c5-a9fd-d7ec3eedfff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
